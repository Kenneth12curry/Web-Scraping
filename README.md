# ğŸš€ FinData IA-M.K

**Plateforme moderne de scraping et d'analyse de donnÃ©es fintech**

Interface web professionnelle avec design dynamique et expÃ©rience utilisateur avancÃ©e.

## âœ¨ FonctionnalitÃ©s principales

- **Authentification sÃ©curisÃ©e** (JWT)
- **Dashboard moderne** : statistiques, quotas, top domaines, historique
- **Scraping intelligent** : Scrape.do (API) + fallback requests
- **Analytics dÃ©taillÃ©es** : graphiques, tendances, erreurs rÃ©centes
- **Export CSV/JSON** des rÃ©sultats
- **Interface React** ultra-moderne (glassmorphism, animations, responsive)
- **ExpÃ©rience utilisateur dynamique** (animations, transitions, feedback visuel)
- **API REST complÃ¨te** pour intÃ©gration
- **Base de donnÃ©es SQLite** pour les stats et l'historique

## ğŸ¨ Design & ExpÃ©rience Utilisateur

- **Glassmorphism** : Effet verre, flou, ombres et gradients
- **Animations** : EntrÃ©e, survol, transitions fluides, feedback visuel
- **Responsive** : AdaptÃ© mobile/tablette/desktop
- **Palette moderne** : Gradients violets/bleus, couleurs vives
- **IcÃ´nes FontAwesome** : UI riche et intuitive
- **Mode sombre automatique** (selon OS)
- **AccessibilitÃ©** : Contrastes, focus, navigation clavier

## ğŸ› ï¸ Stack technique

- **Backend** : Flask, JWT, SQLite, Scrape.do, CORS
- **Frontend** : React, Bootstrap 5, Chart.js, FontAwesome
- **API** : RESTful, endpoints sÃ©curisÃ©s, gestion d'erreurs
- **Scripts** : Batch Windows pour dÃ©marrage facile

## ğŸ“ Structure du projet

```
Test/
â”œâ”€â”€ backend/                 # API Flask
â”‚   â”œâ”€â”€ app.py              # Application principale
â”‚   â”œâ”€â”€ requirements.txt    # DÃ©pendances Python
â”‚   â””â”€â”€ stats.db           # Base de donnÃ©es SQLite
â”œâ”€â”€ frontend-react/         # Interface React
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ components/     # Composants React
â”‚   â”‚   â”œâ”€â”€ services/       # Services API
â”‚   â”‚   â”œâ”€â”€ config.js       # Configuration centralisÃ©e
â”‚   â”‚   â””â”€â”€ App.js         # Application principale
â”‚   â””â”€â”€ package.json       # DÃ©pendances Node.js
â”œâ”€â”€ .env                   # Variables d'environnement
â”œâ”€â”€ test_app.py           # Script de test API
â”œâ”€â”€ start.bat             # Script de dÃ©marrage Windows
â””â”€â”€ README.md             # Ce fichier
```

## ğŸš€ Installation & DÃ©marrage

### 1. PrÃ©requis
- Python 3.8+
- Node.js 16+
- npm

### 2. Configuration de l'environnement
CrÃ©ez un fichier `.env` Ã  la racine du projet :

```env
SCRAPEDO_API_KEY=your_scrapedo_token_here
GROQ_API_KEY=your_groq_token_here
JWT_SECRET_KEY=your_jwt_secret_here
ADMIN_USERNAME=admin
ADMIN_PASSWORD=admin123
```

### 3. Installation du backend
```bash
# Activer l'environnement virtuel
env\Scripts\activate

# Installer les dÃ©pendances Python
cd backend
pip install -r requirements.txt

# DÃ©marrer l'API
python app.py
```

L'API sera disponible sur `http://localhost:8080`

### 4. Installation du frontend
```bash
# Dans un nouveau terminal
cd frontend-react

# Installer les dÃ©pendances
npm install

# DÃ©marrer l'application React
npm start
```

L'interface sera disponible sur `http://localhost:3000`

### 5. DÃ©marrage rapide (Windows)
Double-cliquez sur `start.bat` pour lancer backend + frontend automatiquement.

## ğŸ” Authentification

**Identifiants par dÃ©faut :**
- **Utilisateur :** `admin`
- **Mot de passe :** `admin123`

âš ï¸ **Important :** Changez ces identifiants en production !

## ğŸ“Š Utilisation

### 1. Connexion
- AccÃ©dez Ã  `http://localhost:3000`
- Connectez-vous avec vos identifiants

### 2. Dashboard
- **Statistiques API** : Utilisation, limites, quotas
- **Configuration** : Statut des services (Scrape.do, Groq)
- **Analytics** : Historique des opÃ©rations

### 3. Scraping
- **URL** : Entrez l'URL du site Ã  scraper
- **MÃ©thode** : Choisissez Scrape.do ou Requests
- **RÃ©sultats** : Articles extraits avec mÃ©tadonnÃ©es
- **Export** : TÃ©lÃ©chargez en CSV ou JSON

### 4. Analytics
- **Graphiques** : Visualisation des donnÃ©es
- **Tendances** : Ã‰volution des performances
- **Erreurs rÃ©centes** : Monitoring des problÃ¨mes

### 5. Documentation
- **API Endpoints** : Documentation complÃ¨te
- **Exemples** : Codes d'exemple pour l'intÃ©gration
- **Configuration** : Guide de configuration

## ğŸ”§ API Endpoints

### Authentification
- `POST /api/auth/login` - Connexion
- `POST /api/auth/logout` - DÃ©connexion

### Dashboard
- `GET /api/dashboard/stats` - Statistiques
- `GET /api/dashboard/analytics` - Analytics

### Scraping
- `POST /api/scraping/extract` - Extraction d'articles

### Utilitaires
- `GET /api/health` - VÃ©rification de santÃ©

## ğŸ¯ Exemples d'utilisation

### Extraction d'articles
```bash
curl -X POST http://localhost:8080/api/scraping/extract \
  -H "Authorization: Bearer YOUR_TOKEN" \
  -H "Content-Type: application/json" \
  -d '{
    "url": "https://www.finextra.com/news/latestnews.aspx?topic=fintech",
    "method": "scrapedo"
  }'
```

### RÃ©cupÃ©ration des statistiques
```bash
curl -X GET http://localhost:8080/api/dashboard/stats \
  -H "Authorization: Bearer YOUR_TOKEN"
```

## ğŸ”’ SÃ©curitÃ©

- **JWT** pour l'authentification
- **CORS** configurÃ© pour les frontends
- **Validation** des entrÃ©es utilisateur
- **Gestion d'erreurs** sÃ©curisÃ©e

## ğŸ“ˆ Monitoring

- **Base de donnÃ©es SQLite** pour les statistiques
- **Logs** des opÃ©rations de scraping
- **Analytics** en temps rÃ©el
- **Historique** des domaines utilisÃ©s

## ğŸš€ DÃ©ploiement

### Production
1. Changez les identifiants par dÃ©faut
2. Utilisez un serveur WSGI (Gunicorn)
3. Configurez un reverse proxy (Nginx)
4. Utilisez HTTPS
5. Configurez les variables d'environnement

### Docker (optionnel)
```bash
# Backend
docker build -t findata-backend ./backend
docker run -p 8080:8080 findata-backend

# Frontend
docker build -t findata-frontend ./frontend-react
docker run -p 3000:3000 findata-frontend
```

## ğŸ› DÃ©pannage

### ProblÃ¨mes courants

1. **Erreur de port** : Changez le port dans `backend/app.py`
2. **CORS** : VÃ©rifiez la configuration dans `backend/app.py`
3. **DÃ©pendances** : Relancez `npm install` ou `pip install -r requirements.txt`
4. **Base de donnÃ©es** : Supprimez `backend/stats.db` pour rÃ©initialiser

### Logs
- **Backend** : Logs dans la console
- **Frontend** : Console du navigateur (F12)

## ğŸ“ Support

- **Email** : diandiallo974@gmail.com
- **Documentation Scrape.do** : https://scrape.do/docs
- **Issues** : CrÃ©ez une issue sur GitHub

## ğŸ“„ Licence

Ce projet est sous licence MIT. Voir le fichier LICENSE pour plus de dÃ©tails.

---

**FinData IA-M.K** - PropulsÃ© par Flask, React, Scrape.do et Groq AI 